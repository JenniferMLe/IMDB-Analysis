{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning for IMDB Dataset\n",
    "\n",
    "Author: Jennifer Le  \n",
    "Date: 1/22/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe code below was used to read in the original titles dataset.\\nTo save space, this 11 million row, nearly 1GB dataset is replaced by a\\nsmaller filtered dataset. \\n\\n# Read in original dataset and delete irrelevant columns and rows\\ndf = pd.read_csv(\"title.basics.tsv\", delimiter=\\'\\t\\', low_memory=False)\\ndf = df.drop(columns=[\\'isAdult\\',\\'originalTitle\\'])\\n\\n# Remove rows where titleType is in list, the ~ symbol negates the isin\\nprint(df[\\'titleType\\'].unique())\\ndf = df[\\n    ~df[\"titleType\"].isin(\\n        [\\'tvEpisode\\',\\'video\\',\\'videoGame\\',\\'tvPilot\\',\\'tvSpecial\\']\\n    )\\n]\\ndf.to_csv(\"titles_reduced.csv\",index=False)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "import numpy \n",
    "\n",
    "'''\n",
    "The code below was used to read in the original titles dataset.\n",
    "To save space, this 11 million row, nearly 1GB dataset is replaced by a\n",
    "smaller filtered dataset. \n",
    "\n",
    "# Read in original dataset and delete irrelevant columns and rows\n",
    "df = pd.read_csv(\"title.basics.tsv\", delimiter='\\t', low_memory=False)\n",
    "df = df.drop(columns=['isAdult','originalTitle'])\n",
    "\n",
    "# Remove rows where titleType is in list, the ~ symbol negates the isin\n",
    "print(df['titleType'].unique())\n",
    "df = df[\n",
    "    ~df[\"titleType\"].isin(\n",
    "        ['tvEpisode','video','videoGame','tvPilot','tvSpecial']\n",
    "    )\n",
    "]\n",
    "df.to_csv(\"titles_reduced.csv\",index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2238148, 7)\n",
      "(1526047, 3)\n",
      "(11401626, 3)\n"
     ]
    }
   ],
   "source": [
    "# add files from google drive to correct folder to \n",
    "# run code block without file-not-found error\n",
    "\n",
    "df_titles = pd.read_csv('../../titles_reduced.csv')\n",
    "df_ratings = pd.read_csv('../../ratings.tsv', delimiter='\\t', low_memory=False)\n",
    "df_crew = pd.read_csv('../../crew.tsv', delimiter='\\t', low_memory=False)\n",
    "\n",
    "print(df_titles.shape)\n",
    "print(df_ratings.shape)\n",
    "print(df_crew.shape)\n",
    "\n",
    "df_combined = pd.merge(df_titles, df_ratings, on='tconst', how='inner')\n",
    "df_combined = pd.merge(df_combined, df_crew, on='tconst', how='inner')\n",
    "\n",
    "# replace null values with 0 or empty space\n",
    "df_combined['startYear'] = df_combined['startYear'].replace({'\\\\N': '0'}) \n",
    "df_combined['endYear'] = df_combined['endYear'].replace({'\\\\N': '0'})        \n",
    "df_combined['runtimeMinutes'] = df_combined['runtimeMinutes'].replace({'\\\\N':'0'})\n",
    "df_combined['genres'] = df_combined['genres'].replace({'\\\\N':''}) \n",
    "df_combined['directors'] = df_combined['directors'].replace({'\\\\N':''}) \n",
    "df_combined['writers'] = df_combined['writers'].replace({'\\\\N':''}) \n",
    "\n",
    "# convert types to save space\n",
    "df_combined['endYear'] = df_combined['endYear'].astype('int32')   \n",
    "df_combined['runtimeMinutes'] = df_combined['runtimeMinutes'].astype('int32')       \n",
    "df_combined['startYear'] = df_combined['startYear'].astype('int32')  \n",
    "\n",
    "df_combined.to_csv('result.csv', index=False)\n",
    "print(df_combined.shape)\n",
    "print(df_combined.dtypes)\n",
    "\n",
    "df_combined.to_csv('imdb_dataset_original.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.read_csv('imdb_dataset_original.csv')\n",
    "df_names = pd.read_csv('../../names.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract columns to make fact tables\n",
    "df_genres = df_combined[['tconst','genres']]\n",
    "df_directors = df_combined[['tconst','directors']]\n",
    "df_writers = df_combined[['tconst','writers']]\n",
    "\n",
    "# drop columns from dimension table because \n",
    "# it will be repetive once fact tables are set up\n",
    "df_combined = df_combined.drop(columns=['genres','writers','directors'])\n",
    "df_combined.to_csv('imdb_dataset_transformed.csv',index=False)\n",
    "\n",
    "# split columns \n",
    "df_genres_split = df_genres['genres'].str.split(pat=',',expand=True, n=2)\n",
    "df_directors_split = df_directors['directors'].str.split(pat=',',expand=True, n=3)\n",
    "df_writers_split = df_writers['writers'].str.split(pat=',',expand=True, n=3)\n",
    "\n",
    "# add new columns for the splited genres\n",
    "df_genres['genres'] = df_genres_split[0]\n",
    "df_genres['genre2'] = df_genres_split[1]\n",
    "df_genres['genre3'] = df_genres_split[2]\n",
    "\n",
    "# add new columns for the splited directors\n",
    "df_directors['directors'] = df_directors_split[0]\n",
    "df_directors['director2'] = df_directors_split[1]\n",
    "df_directors['director3'] = df_directors_split[2]\n",
    "\n",
    "# add new columns for the splited writers\n",
    "df_writers['writers'] = df_writers_split[0]\n",
    "df_writers['writer2'] = df_writers_split[1]\n",
    "df_writers['writer3'] = df_writers_split[2]\n",
    "\n",
    "# change column names\n",
    "df_genres = df_genres.rename(columns={'genres':'genre1'})\n",
    "df_directors = df_directors.rename(columns={'directors':'director1'})\n",
    "df_writers = df_writers.rename(columns={'writers':'writer1'})\n",
    "\n",
    "# function to replace name id with actual name\n",
    "def replace_id_with_names(df, df_names, column_name):\n",
    "    df = pd.merge(df,df_names, \n",
    "        left_on=column_name, right_on='nconst',how ='left')\n",
    "\n",
    "    df[column_name] = df['primaryName']\n",
    "    df = df.drop(columns=['nconst','primaryName'])\n",
    "\n",
    "    return df\n",
    "\n",
    "# replace id of directors and writers with names\n",
    "df_directors = replace_id_with_names(df_directors, df_names, 'director1')\n",
    "df_directors = replace_id_with_names(df_directors, df_names, 'director2')\n",
    "df_directors = replace_id_with_names(df_directors, df_names, 'director3')\n",
    "df_writers = replace_id_with_names(df_writers, df_names, 'writer1')\n",
    "df_writers = replace_id_with_names(df_writers, df_names, 'writer2')\n",
    "df_writers = replace_id_with_names(df_writers, df_names, 'writer3')\n",
    "\n",
    "def create_fact_tables(df, new_name, csv_file_name):\n",
    "    # transform table to long format so all category values are in one column\n",
    "    df = pd.melt(df, id_vars='tconst', value_vars=df.columns[1:])\n",
    "    df = df.rename(columns={'variable':'col_num','value':new_name})\n",
    "\n",
    "    # delete rows with no genre, director, or writer\n",
    "    df = df[df[new_name].notna()]\n",
    "\n",
    "    # write transformed table to csv\n",
    "    df.to_csv(csv_file_name,index=False)\n",
    "\n",
    "create_fact_tables(df_genres, 'genre', 'genres.csv')\n",
    "create_fact_tables(df_directors, 'director', 'directors.csv')\n",
    "create_fact_tables(df_writers, 'writer', 'writers.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs418env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
